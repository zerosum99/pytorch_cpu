# 주어진 환경과 상호작용을 통해 성장하는 DQN

간단한 게임환경 안에서 스스로 성장하는 DQN 에이전트를 만들어봅니다.

  * [개념] 강화학습과 DQN기초
  * [팁] OpenAI Gym
  * [프로젝트 1] 카트폴 게임 마스터하기
  * 더 보기


## 강화학습과 DQN기초

사람은 스스로 성장합니다.
선생님이 가르쳐 주는 지식도 중요하지만 자기주도적 학습을 하는 것도 중요합니다.
기계학습에도 비슷한 영역이 있습니다.
주어진 환경과 상호작용을 통해 가장 좋은 점수를 받는 쪽으로
성장하는 머신러닝 분야를 "강화학습" 이라고 부릅니다.
비유를 들자면 앞서 배웠던 학습 방법들이 우리가 원하는
교재(데이터셋)를 외우게 하는 주입식 학습법이고 강화학습은
자기주도적 학습법이라고 볼 수 있습니다.
강화학습에서 사람은 목표를 설정해주고
당근과 채찍을 이용해 성장시키는 코치입니다.

누가 가르쳐주지 않았는데도 우리는 각자 나름대로 뛰는법을 배웠습니다.
처음 뛰었을때를 상상해보세요. 처음부터 숨을 어떻게 쉬고, 팔을 어떻게 흔들고,
다리 근육을 어떻게 사용하는지 머릿속으로 일일이 생각을 하면
오히려 부자연스러워 지기 마련입니다.
일어섰다가 넘어지기를 반복하며 우리들은 시행착오를 통해 걷고 뛰는 법을 배웁니다.
강화학습 에이전트도 주어진 환경안에서 여러가지의 시행착오를 통해 좋은 피드백을
좋은쪽으로 최적화를 하는 것이 목표입니다.

![rl](./assets/rl.png)

강화학습은 크게 상태(State), 에이전트(Agent), 행동(Action), 보상(Reward)의
4가지 요소로 나눌 수 있습니다.
환경은 우리가 마스터하기 원하는 무대이고 시간에 따라 다른 상태를 제공합니다.
에이전트는 인공지능 플레이어입니다.
그리고 에이전트가 환경 안에서 여러가지 행동을 함에 따라
나오는 피드백을 보상, 혹은 리워드라고 부릅니다.


2013년 구글 딥마인드는 NIPS라는 학회에서
"딥 강화학습을 이용하여 아타리 게임하기"
(Playing Atari with Deep Reinforcement Learning)라는 논문을 냅니다.
이 논문은 Deep Q-Network, 혹은 줄여 DQN이라고 부르는 알고리즘을 이용하여
아타리사의 유명한 게임들에서 사람보다 월등한 성능을 내는 인공지능을 만들어 많은 주목을 받았습니다.
사전에 주어진 정보 없이 화면과 조종키 몇개만 주어진 환경에서 기존 알고리즘들보다
월등하게 좋은 성능을 내었고, 심지어 특정 게임에서는
버그를 찾아 치사한 방법으로 이기는 모습도 보여주었습니다.
딥마인드사는이 업적을 바탕으로 딥 강화학습이라는 연구 분야를 개척하고 구글에 인수가 됩니다.


“얼마나 대단한 알고리즘이길래?” 라고 하실 수 있습니다.
하지만 인공신경망과 비슷하게 코드로 담아보면 몇줄 안되는 것을 발견할 수 있습니다.

DQN은 갑자기 새롭게 튀어나온 아이디어라기 보다는 고전적인
Q-Learning이라는 알고리즘에 뉴럴넷과 여러가지 테크닉을 접목한 결과입니다.
