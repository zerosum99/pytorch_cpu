{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data,datasets\n",
    "from torchtext.vocab import GloVe,FastText,CharNGram\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torchtext.datasets.imdb import IMDB\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.2 (default, Dec 29 2018, 06:19:36) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, batch_first=True,fix_length=40,)\n",
    "LABEL = data.Field(sequential=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.datasets.imdb.IMDB"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7f99d12d2ef0>, 'label': <torchtext.data.field.Field object at 0x7f99d12d2f60>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'text': ['girlfight', 'is', 'like', 'your', \"grandmother's\", 'cooking:', 'same', 'old', 'recipe', \"you've\", 'tried', 'a', 'million', 'times', 'before,', 'yet', 'somehow', 'transformed', 'into', 'something', 'fresh', 'and', 'new.', 'try', 'and', 'explain', 'the', 'story', 'to', 'people', 'who', \"haven't\", 'seen', 'it', 'before:', 'a', 'young', 'women', 'from', 'the', 'wrong', 'side', 'of', 'the', 'tracks', 'attempts', 'to', 'improve', 'her', 'situation', 'by', 'taking', 'up', 'boxing', 'whilst', 'dealing', 'with', 'a', 'bitter,', 'obstructive', 'father', 'and', 'her', 'growing', 'attraction', 'to', 'a', 'male', 'rival.', 'watch', 'them', 'roll', 'their', 'eyes', 'at', 'the', 'string', 'of', 'clichés,', 'and', \"they're\", 'right:', 'it', '*is*', 'clichéd.', 'yet', 'i', 'was', 'hypnotized', 'by', 'how', 'well', 'this', 'film', 'works,', 'due', 'to', 'the', 'frequently', 'superb', 'acting', 'and', 'dialogue,', 'and', 'sensitive', 'direction', 'that', 'makes', 'it', \"'new'.\", 'i', 'avoided', 'this', 'at', 'the', 'cinema', 'because', 'it', 'looked', 'like', 'complete', 'crap', 'but', \"don't\", 'make', 'the', 'same', 'mistake', 'i', 'did.', 'definiately', 'worth', 'a', 'look.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
    "LABEL.build_vocab(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pos': 12500, 'neg': 12500})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7f99d12d2ef0>, 'label': <torchtext.data.field.Field object at 0x7f99d12d2f60>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'text': ['girlfight', 'is', 'like', 'your', \"grandmother's\", 'cooking:', 'same', 'old', 'recipe', \"you've\", 'tried', 'a', 'million', 'times', 'before,', 'yet', 'somehow', 'transformed', 'into', 'something', 'fresh', 'and', 'new.', 'try', 'and', 'explain', 'the', 'story', 'to', 'people', 'who', \"haven't\", 'seen', 'it', 'before:', 'a', 'young', 'women', 'from', 'the', 'wrong', 'side', 'of', 'the', 'tracks', 'attempts', 'to', 'improve', 'her', 'situation', 'by', 'taking', 'up', 'boxing', 'whilst', 'dealing', 'with', 'a', 'bitter,', 'obstructive', 'father', 'and', 'her', 'growing', 'attraction', 'to', 'a', 'male', 'rival.', 'watch', 'them', 'roll', 'their', 'eyes', 'at', 'the', 'string', 'of', 'clichés,', 'and', \"they're\", 'right:', 'it', '*is*', 'clichéd.', 'yet', 'i', 'was', 'hypnotized', 'by', 'how', 'well', 'this', 'film', 'works,', 'due', 'to', 'the', 'frequently', 'superb', 'acting', 'and', 'dialogue,', 'and', 'sensitive', 'direction', 'that', 'makes', 'it', \"'new'.\", 'i', 'avoided', 'this', 'at', 'the', 'cinema', 'because', 'it', 'looked', 'like', 'complete', 'crap', 'but', \"don't\", 'make', 'the', 'same', 'mistake', 'i', 'did.', 'definiately', 'worth', 'a', 'look.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = vars(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['freqs', 'itos', 'stoi', 'vectors'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.7724, -0.1800,  0.2072,  ...,  0.6736,  0.2263, -0.2919],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=-1)\n",
    "\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbNet(nn.Module):\n",
    "    def __init__(self,emb_size,hidden_size1,hidden_size2=400):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(emb_size,hidden_size1)\n",
    "        self.fc = nn.Linear(hidden_size2,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeds = self.embedding(x).view(x.size(0),-1)\n",
    "        out = self.fc(embeds)\n",
    "        return F.log_softmax(out,dim=-1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbNet(len(TEXT.vocab.stoi),10)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=-1,shuffle=True)\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , batch in enumerate(data_loader):\n",
    "        text , target = batch.text , batch.label\n",
    "        if is_cuda:\n",
    "            text,target = text.cuda(),target.cuda()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output,target,size_average=False).data\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct.item()/len(data_loader.dataset)\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taewan/.local/lib/python3.7/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.73 and training accuracy is 13009/25000     52.04\n",
      "validation loss is   0.7 and validation accuracy is 13360/25000     53.44\n",
      "training loss is  0.68 and training accuracy is 14420/25000     57.68\n",
      "validation loss is  0.68 and validation accuracy is 14590/25000     58.36\n",
      "training loss is  0.64 and training accuracy is 15903/25000     63.61\n",
      "validation loss is  0.65 and validation accuracy is 15828/25000     63.31\n",
      "training loss is  0.59 and training accuracy is 17104/25000     68.42\n",
      "validation loss is  0.62 and validation accuracy is 16442/25000     65.77\n",
      "training loss is  0.54 and training accuracy is 18078/25000     72.31\n",
      "validation loss is  0.62 and validation accuracy is 16888/25000     67.55\n",
      "training loss is  0.51 and training accuracy is 18664/25000     74.66\n",
      "validation loss is  0.61 and validation accuracy is 17158/25000     68.63\n",
      "training loss is  0.48 and training accuracy is 19176/25000      76.7\n",
      "validation loss is   0.6 and validation accuracy is 17435/25000     69.74\n",
      "training loss is  0.45 and training accuracy is 19621/25000     78.48\n",
      "validation loss is   0.6 and validation accuracy is 17509/25000     70.04\n",
      "training loss is  0.43 and training accuracy is 20044/25000     80.18\n",
      "validation loss is   0.6 and validation accuracy is 17569/25000     70.28\n",
      "CPU times: user 13.4 s, sys: 1.15 s, total: 14.5 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]\n",
    "\n",
    "for epoch in range(1,10):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 학습 Glove 워드 임베딩 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, batch_first=True,fix_length=40,)\n",
    "LABEL = data.Field(sequential=False,)\n",
    "\n",
    "train, test = IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "TEXT.build_vocab(train,test, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
    "LABEL.build_vocab(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbNet(nn.Module):\n",
    "    def __init__(self,emb_size,hidden_size1,hidden_size2=400):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(emb_size,hidden_size1)\n",
    "        self.fc1 = nn.Linear(hidden_size2,3)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeds = self.embedding(x).view(x.size(0),-1)\n",
    "        out = self.fc1(embeds)\n",
    "        return F.log_softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbNet(len(TEXT.vocab.stoi),300,12000)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data = TEXT.vocab.vectors.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(model.parameters(),lr=0.001)\n",
    "optimizer = optim.Adam([ param for param in model.parameters() if param.requires_grad == True],lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=64, device=-1,shuffle=True)\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , batch in enumerate(data_loader):\n",
    "        text , target = batch.text , batch.label\n",
    "        if is_cuda:\n",
    "            text,target = text.cuda(),target.cuda()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output,target,size_average=False).data\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct.item()/len(data_loader.dataset)\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.66 and training accuracy is 15714/25000     62.86\n",
      "validation loss is  0.65 and validation accuracy is 16218/25000     64.87\n",
      "training loss is  0.57 and training accuracy is 17674/25000      70.7\n",
      "validation loss is  0.65 and validation accuracy is 16555/25000     66.22\n",
      "training loss is  0.53 and training accuracy is 18425/25000      73.7\n",
      "validation loss is  0.67 and validation accuracy is 16425/25000      65.7\n",
      "training loss is  0.51 and training accuracy is 18779/25000     75.12\n",
      "validation loss is  0.69 and validation accuracy is 16358/25000     65.43\n",
      "training loss is  0.49 and training accuracy is 19145/25000     76.58\n",
      "validation loss is  0.72 and validation accuracy is 16375/25000      65.5\n",
      "training loss is  0.48 and training accuracy is 19169/25000     76.68\n",
      "validation loss is  0.74 and validation accuracy is 16361/25000     65.44\n",
      "training loss is  0.47 and training accuracy is 19435/25000     77.74\n",
      "validation loss is  0.76 and validation accuracy is 16207/25000     64.83\n",
      "training loss is  0.47 and training accuracy is 19454/25000     77.82\n",
      "validation loss is   0.8 and validation accuracy is 16066/25000     64.26\n",
      "training loss is  0.46 and training accuracy is 19630/25000     78.52\n",
      "validation loss is  0.78 and validation accuracy is 16288/25000     65.15\n",
      "CPU times: user 8.56 s, sys: 352 ms, total: 8.91 s\n",
      "Wall time: 8.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1,10):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.44 and training accuracy is 19858/25000     79.43\n",
      "validation loss is   0.8 and validation accuracy is 16197/25000     64.79\n",
      "training loss is  0.44 and training accuracy is 19788/25000     79.15\n",
      "validation loss is  0.82 and validation accuracy is 16121/25000     64.48\n",
      "training loss is  0.44 and training accuracy is 19901/25000      79.6\n",
      "validation loss is  0.83 and validation accuracy is 16113/25000     64.45\n",
      "training loss is  0.43 and training accuracy is 20016/25000     80.06\n",
      "validation loss is  0.85 and validation accuracy is 16093/25000     64.37\n",
      "training loss is  0.43 and training accuracy is 20029/25000     80.12\n",
      "validation loss is  0.87 and validation accuracy is 15947/25000     63.79\n",
      "training loss is  0.42 and training accuracy is 20139/25000     80.56\n",
      "validation loss is  0.89 and validation accuracy is 15935/25000     63.74\n",
      "training loss is  0.42 and training accuracy is 20145/25000     80.58\n",
      "validation loss is  0.88 and validation accuracy is 16042/25000     64.17\n",
      "training loss is  0.41 and training accuracy is 20288/25000     81.15\n",
      "validation loss is   0.9 and validation accuracy is 15938/25000     63.75\n",
      "training loss is  0.42 and training accuracy is 20254/25000     81.02\n",
      "validation loss is  0.94 and validation accuracy is 15897/25000     63.59\n",
      "CPU times: user 8.7 s, sys: 427 ms, total: 9.13 s\n",
      "Wall time: 9.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1,10):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
