{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models.inception import inception_v3\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp,cmap=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp,cmap)\n",
    "    \n",
    "class LayerActivations():\n",
    "    features=[]\n",
    "    \n",
    "    def __init__(self,model):\n",
    "        self.features = []\n",
    "        self.hook = model.register_forward_hook(self.hook_fn)\n",
    "    \n",
    "    def hook_fn(self,module,input,output):\n",
    "        \n",
    "        self.features.extend(output.view(output.size(0),-1).cpu().data)\n",
    "\n",
    "    \n",
    "    def remove(self):\n",
    "        \n",
    "        self.hook.remove()\n",
    "    \n",
    "class FeaturesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,featlst,labellst):\n",
    "        self.featlst = featlst\n",
    "        self.labellst = labellst\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return (self.featlst[index],self.labellst[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labellst)\n",
    "    \n",
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , (data,target) in enumerate(data_loader):\n",
    "        if is_cuda:\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        data , target = Variable(data,volatile),Variable(target)\n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        \n",
    "        running_loss += F.cross_entropy(output,target,size_average=False).data\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct.item()/len(data_loader.dataset)\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((299,299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For Dogs & Cats dataset\n",
    "train_dset = ImageFolder('../Chapter03/dogsandcats/train/',transform=data_transform)\n",
    "val_dset = ImageFolder('../Chapter03/dogsandcats/valid/',transform=data_transform)\n",
    "classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imshow(train_dset[150][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating data loader for training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dset,batch_size=32,shuffle=False,num_workers=3)\n",
    "val_loader = DataLoader(val_dset,batch_size=32,shuffle=False,num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Inception V3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_inception = inception_v3(pretrained=True)\n",
    "my_inception.aux_logits = False\n",
    "for p in my_inception.parameters():\n",
    "    p.requires_grad = False\n",
    "if is_cuda:\n",
    "    my_inception = my_inception.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Convolutional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LayerActivations object to store the output of inception model at a particular layer.\n",
    "trn_features = LayerActivations(my_inception.Mixed_7c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing all the data through the model , as a side effect the outputs will get stored \n",
    "# in the features list of the LayerActivations object. \n",
    "trn_labels = []\n",
    "for da,la in train_loader:\n",
    "    _ = my_inception(da.cuda())\n",
    "    trn_labels.extend(la)\n",
    "trn_features.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same process for validation dataset .\n",
    "\n",
    "val_features = LayerActivations(my_inception.Mixed_7c)\n",
    "val_labels = []\n",
    "for da,la in val_loader:\n",
    "    _ = my_inception(Variable(da.cuda()))\n",
    "    val_labels.extend(la)\n",
    "val_features.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_features.features[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trn_features.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and validation feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for pre computed features for train and validation data sets\n",
    "\n",
    "trn_feat_dset = FeaturesDataset(trn_features.features,trn_labels)\n",
    "val_feat_dset = FeaturesDataset(val_features.features,val_labels)\n",
    "\n",
    "#Data loaders for pre computed features for train and validation data sets\n",
    "\n",
    "trn_feat_loader = DataLoader(trn_feat_dset,batch_size=64,shuffle=True)\n",
    "val_feat_loader = DataLoader(val_feat_dset,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_size,out_size,training=True):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_size,out_size)\n",
    "\n",
    "    def forward(self,inp):\n",
    "        out = F.dropout(inp, training=self.training)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# The size of the output from the selected convolution feature \n",
    "fc_in_size = 131072\n",
    "\n",
    "fc = FullyConnectedModel(fc_in_size,classes)\n",
    "if is_cuda:\n",
    "    fc = fc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(fc.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]\n",
    "for epoch in range(1,10):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,fc,trn_feat_loader,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,fc.eval(),val_feat_loader,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr']= 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,10):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,fc,trn_feat_loader,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,fc,val_feat_loader,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,10):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,fc,trn_feat_loader,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,fc,val_feat_loader,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
